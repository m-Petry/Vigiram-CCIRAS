{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74ea907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso.\n",
      "Pandas versão: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 1: IMPORTAÇÕES (CORRIGIDO)\n",
    "# ==============================================================================\n",
    "# Bibliotecas padrão para manipulação de arquivos e sistema operacional\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Biblioteca principal para manipulação e análise de dados\n",
    "import pandas as pd\n",
    "\n",
    "# Usado para escrever em arquivos Excel com múltiplas abas\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# A linha abaixo foi removida pois 'dataframe_to_sheet' não é mais usada\n",
    "# from openpyxl.utils.dataframe import dataframe_to_sheet\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso.\")\n",
    "print(f\"Pandas versão: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "942162d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta de DADOS (Entrada): C:\\Users\\marcelo.petry\\Documents\\CCIRAS\\vigiram\\data\n",
      "Pasta de RELATÓRIOS (Saída): C:\\Users\\marcelo.petry\\Documents\\CCIRAS\\vigiram\\outputs\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 2: CONFIGURAÇÃO DE DIRETÓRIOS\n",
    "# ==============================================================================\n",
    "try:\n",
    "    # Em um ambiente de script .py, __file__ existe\n",
    "    NB_DIR = Path(__file__).parent.resolve()\n",
    "except NameError:\n",
    "    # Em um notebook Jupyter, usamos Path() para obter o diretório atual\n",
    "    NB_DIR = Path().resolve()\n",
    "\n",
    "# Assume que a estrutura é /repo/notebooks/ e os dados estão em /repo/data\n",
    "REPO_ROOT = NB_DIR.parent\n",
    "DATA_DIR = (REPO_ROOT / \"data\").resolve()\n",
    "OUT_DIR = (REPO_ROOT / \"outputs\").resolve()\n",
    "\n",
    "# Cria os diretórios se eles não existirem\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Pasta de DADOS (Entrada): {DATA_DIR}\")\n",
    "print(f\"Pasta de RELATÓRIOS (Saída): {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98948f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 3: FUNÇÃO PARA CONSOLIDAR DADOS-FONTE (VERSÃO CORRIGIDA E FINAL)\n",
    "# ==============================================================================\n",
    "def consolidar_dados_mensais(\n",
    "    mes_ano_base: str, pasta_dados: Path\n",
    ") -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Lê o arquivo base 'vigiram' e o enriquece com a coluna 'Material Análise' do arquivo 'its',\n",
    "    que é a fonte correta para o tipo de amostra.\n",
    "\n",
    "    Args:\n",
    "        mes_ano_base (str): A base do nome do arquivo (ex: \"jan25\").\n",
    "        pasta_dados (Path): O caminho para o diretório 'data'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame ou None: Um DataFrame consolidado ou None se os arquivos\n",
    "                              principais não forem encontrados.\n",
    "    \"\"\"\n",
    "    print(f\"🔄 Processando base: {mes_ano_base}...\")\n",
    "    try:\n",
    "        # 1. Carregar os arquivos de entrada\n",
    "        path_base = pasta_dados / f\"vigiram-{mes_ano_base}.csv\"\n",
    "        path_its = pasta_dados / f\"its-{mes_ano_base}.csv\"\n",
    "\n",
    "        df_base = pd.read_csv(path_base, dtype=str, low_memory=False)\n",
    "        df_its = pd.read_csv(path_its, dtype=str, low_memory=False)\n",
    "\n",
    "        # 2. Preparar o DataFrame 'its' para o merge\n",
    "        # Renomeia a coluna chave para 'solicitacao' e a coluna de interesse para um nome único\n",
    "        df_its_renamed = df_its.rename(\n",
    "            columns={\n",
    "                \"Solicitação\": \"solicitacao\",\n",
    "                \"Material Análise\": \"fonte_correta_amostra\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Seleciona apenas a chave e a coluna de interesse para evitar duplicatas e conflitos\n",
    "        df_its_subset = df_its_renamed[[\"solicitacao\", \"fonte_correta_amostra\"]]\n",
    "\n",
    "        # 3. Executar o merge\n",
    "        # Usamos um 'left merge' para garantir que todos os registros do arquivo base sejam mantidos.\n",
    "        # As informações de amostra do 'its' serão adicionadas onde houver correspondência de 'solicitacao'.\n",
    "        df_final = pd.merge(df_base, df_its_subset, on=\"solicitacao\", how=\"left\")\n",
    "\n",
    "        print(\n",
    "            f\"✅ Dados de '{mes_ano_base}' consolidados. Fonte de amostra ('Material Análise' do ITS) vinculada.\"\n",
    "        )\n",
    "        return df_final\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\n",
    "            f\"⚠️ Arquivo principal faltando para '{mes_ano_base}': {e.filename}. Pulando este mês.\"\n",
    "        )\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro inesperado ao processar '{mes_ano_base}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b631b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 4: FUNÇÃO PARA LIMPEZA E ENRIQUECIMENTO DOS DADOS (VERSÃO CORRIGIDA E FINAL)\n",
    "# ==============================================================================\n",
    "def limpar_e_preparar_dados(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Limpa, formata e enriquece o DataFrame consolidado para análise da CCIRAS.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): O DataFrame bruto consolidado.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: O DataFrame pronto para a geração dos relatórios.\n",
    "    \"\"\"\n",
    "    # Renomear colunas para nomes mais intuitivos e remover espaços\n",
    "    mapeamento_colunas = {\n",
    "        # **AQUI ESTÁ A CORREÇÃO PRINCIPAL**: Mapeamos a coluna que foi\n",
    "        # corretamente extraída do ITS na etapa de consolidação.\n",
    "        \"fonte_correta_amostra\": \"tipo_amostra\",\n",
    "        \"data_area_executora\": \"data_liberacao\",\n",
    "        \"paciente\": \"nome_paciente\",\n",
    "        \"solicitacao\": \"prontuario\",\n",
    "        \"unidade_solicitante\": \"unidade_solicitante\",\n",
    "        \"Antibiótico\": \"antibiotico_testado\",\n",
    "        \"RSI\": \"resultado_rsi\",\n",
    "        \"Mic\": \"valor_mic\",\n",
    "        \"Perfil de Resistência\": \"perfil_resistencia\",\n",
    "        \"origem\": \"origem_atendimento\",\n",
    "        \"Tipo Alta\": \"tipo_alta\",\n",
    "    }\n",
    "    # Renomeia apenas as colunas que existem no DataFrame\n",
    "    df = df.rename(\n",
    "        columns={k: v for k, v in mapeamento_colunas.items() if k in df.columns}\n",
    "    )\n",
    "\n",
    "    # Padronização de texto (remove espaços e converte para maiúsculas)\n",
    "    for col in df.select_dtypes(include=\"object\").columns:\n",
    "        df[col] = df[col].str.strip().str.upper()\n",
    "\n",
    "    # Conversão de datas\n",
    "    df[\"data_liberacao\"] = pd.to_datetime(df[\"data_liberacao\"], errors=\"coerce\")\n",
    "\n",
    "    # Preencher valores nulos em colunas críticas para evitar erros na análise\n",
    "    colunas_para_preencher = [\n",
    "        \"microorganismo\",\n",
    "        \"antibiotico_testado\",\n",
    "        \"resultado_rsi\",\n",
    "        \"unidade_solicitante\",\n",
    "        \"tipo_amostra\",\n",
    "    ]\n",
    "    for col in colunas_para_preencher:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(\"N/A\")\n",
    "        else:\n",
    "            # Se uma coluna crítica ainda não existir, cria com N/A para evitar erros futuros\n",
    "            df[col] = \"N/A\"\n",
    "\n",
    "    # Criar coluna de origem simplificada (Hospitalar vs. Ambulatorial)\n",
    "    df[\"origem_atendimento_simplificada\"] = df[\"origem_atendimento\"].apply(\n",
    "        lambda x: (\n",
    "            \"AMBULATORIAL\"\n",
    "            if isinstance(x, str) and x.startswith(\"AMBUL\")\n",
    "            else \"HOSPITALAR\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e65356a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 5: FUNÇÕES PARA GERAÇÃO DAS ABAS ANALÍTICAS (VERSÃO CORRIGIDA)\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def gerar_aba_dashboard(df: pd.DataFrame, df_contagens: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Gera a aba de Dashboard com indicadores chave.\"\"\"\n",
    "    total_pac_positivos = df_contagens.get(\"positivos\", 0)\n",
    "    total_pac_negativos = df_contagens.get(\"negativos\", 0)\n",
    "\n",
    "    total_amostras = df[\"amostra\"].nunique()\n",
    "    total_isolados = df[df[\"microorganismo\"] != \"N/A\"][\"microorganismo\"].count()\n",
    "\n",
    "    isolados_acineto = df[df[\"microorganismo\"] == \"ACINETOBACTER BAUMANNII\"].shape[0]\n",
    "    isolados_klebsiella = df[df[\"microorganismo\"] == \"KLEBSIELLA PNEUMONIAE\"].shape[0]\n",
    "    isolados_pseudo = df[df[\"microorganismo\"] == \"PSEUDOMONAS AERUGINOSA\"].shape[0]\n",
    "    isolados_staph = df[df[\"microorganismo\"] == \"STAPHYLOCOCCUS AUREUS\"].shape[0]\n",
    "    isolados_entero = df[\n",
    "        df[\"microorganismo\"].str.contains(\"ENTEROCOCCUS\", na=False)\n",
    "    ].shape[0]\n",
    "\n",
    "    def calcular_taxa_resistencia(mic, antib):\n",
    "        testes = df[\n",
    "            (df[\"microorganismo\"] == mic) & (df[\"antibiotico_testado\"] == antib)\n",
    "        ]\n",
    "        if testes.empty:\n",
    "            return 0.0\n",
    "        resistentes = testes[testes[\"resultado_rsi\"] == \"R\"].shape[0]\n",
    "        return (resistentes / len(testes) * 100) if len(testes) > 0 else 0.0\n",
    "\n",
    "    taxa_acineto_carba = calcular_taxa_resistencia(\n",
    "        \"ACINETOBACTER BAUMANNII\", \"MEROPENEM\"\n",
    "    )\n",
    "    taxa_mrsa = calcular_taxa_resistencia(\"STAPHYLOCOCCUS AUREUS\", \"OXACILINA\")\n",
    "    taxa_vre = calcular_taxa_resistencia(\"ENTEROCOCCUS FAECALIS\", \"VANCOMICINA\")\n",
    "\n",
    "    data = {\n",
    "        \"Indicador\": [\n",
    "            \"Total de Pacientes com Cultura Positiva\",\n",
    "            \"Total de Pacientes com Cultura Negativa\",\n",
    "            \"Total de Amostras Coletadas\",\n",
    "            \"Total de Microrganismos Isolados\",\n",
    "            \"Nº de Isolados de Acinetobacter baumannii\",\n",
    "            \"Nº de Isolados de Klebsiella pneumoniae\",\n",
    "            \"Nº de Isolados de Pseudomonas aeruginosa\",\n",
    "            \"Nº de Isolados de Staphylococcus aureus\",\n",
    "            \"Nº de Isolados de Enterococcus spp.\",\n",
    "            \"% de A. baumannii resistente a Carbapenêmicos\",\n",
    "            \"% de S. aureus resistente à Oxacilina (MRSA)\",\n",
    "            \"% de Enterococcus resistente à Vancomicina (VRE)\",\n",
    "        ],\n",
    "        \"Valor\": [\n",
    "            total_pac_positivos,\n",
    "            total_pac_negativos,\n",
    "            total_amostras,\n",
    "            total_isolados,\n",
    "            isolados_acineto,\n",
    "            isolados_klebsiella,\n",
    "            isolados_pseudo,\n",
    "            isolados_staph,\n",
    "            isolados_entero,\n",
    "            f\"{taxa_acineto_carba:.1f}%\",\n",
    "            f\"{taxa_mrsa:.1f}%\",\n",
    "            f\"{taxa_vre:.1f}%\",\n",
    "        ],\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def gerar_aba_perfil_sensibilidade(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Gera a aba de Perfil de Sensibilidade (Antibiograma).\"\"\"\n",
    "    df_analise = df[df[\"microorganismo\"] != \"N/A\"].copy()\n",
    "\n",
    "    pivot = df_analise.pivot_table(\n",
    "        index=[\"microorganismo\", \"antibiotico_testado\"],\n",
    "        columns=\"resultado_rsi\",\n",
    "        values=\"prontuario\",\n",
    "        aggfunc=\"count\",\n",
    "        fill_value=0,\n",
    "    )\n",
    "\n",
    "    for col in [\"S\", \"R\", \"I\"]:\n",
    "        if col not in pivot.columns:\n",
    "            pivot[col] = 0\n",
    "\n",
    "    pivot[\"Nº de Testes\"] = pivot.sum(axis=1)\n",
    "\n",
    "    pivot[\"% Sensível (S)\"] = (pivot[\"S\"] / pivot[\"Nº de Testes\"] * 100).round(1)\n",
    "    pivot[\"% Intermediário (I)\"] = (pivot[\"I\"] / pivot[\"Nº de Testes\"] * 100).round(1)\n",
    "    pivot[\"% Resistente (R)\"] = (pivot[\"R\"] / pivot[\"Nº de Testes\"] * 100).round(1)\n",
    "\n",
    "    return pivot.reset_index()[\n",
    "        [\n",
    "            \"microorganismo\",\n",
    "            \"antibiotico_testado\",\n",
    "            \"Nº de Testes\",\n",
    "            \"% Sensível (S)\",\n",
    "            \"% Intermediário (I)\",\n",
    "            \"% Resistente (R)\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "\n",
    "# **AQUI ESTÁ A MUDANÇA PRINCIPAL**: Novo formato para a aba de Unidade\n",
    "def gerar_aba_distribuicao_unidade(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gera a aba de Distribuição de Microrganismos por Unidade/Setor em formato LONGO.\n",
    "    \"\"\"\n",
    "    df_analise = df[df[\"microorganismo\"] != \"N/A\"].copy()\n",
    "\n",
    "    distribuicao = (\n",
    "        df_analise.groupby([\"unidade_solicitante\", \"microorganismo\"])[\"prontuario\"]\n",
    "        .nunique()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    distribuicao = distribuicao.rename(columns={\"prontuario\": \"Nº de Pacientes Únicos\"})\n",
    "\n",
    "    distribuicao = distribuicao.sort_values(\n",
    "        by=[\"unidade_solicitante\", \"Nº de Pacientes Únicos\"], ascending=[True, False]\n",
    "    )\n",
    "\n",
    "    return distribuicao\n",
    "\n",
    "\n",
    "# **AQUI ESTÁ A MUDANÇA PRINCIPAL**: Novo formato para a aba de Amostra\n",
    "def gerar_aba_distribuicao_amostra(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gera a aba de Distribuição de Microrganismos por Tipo de Amostra em formato LONGO.\n",
    "    \"\"\"\n",
    "    df_analise = df[\n",
    "        (df[\"microorganismo\"] != \"N/A\") & (df[\"tipo_amostra\"] != \"N/A\")\n",
    "    ].copy()\n",
    "\n",
    "    if df_analise.empty:\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                \"Tipo de Amostra\": [\"Nenhum dado de amostra encontrado para análise.\"],\n",
    "                \"Microrganismo\": [\"\"],\n",
    "                \"Nº de Pacientes Únicos\": [0],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    distribuicao = (\n",
    "        df_analise.groupby([\"tipo_amostra\", \"microorganismo\"])[\"prontuario\"]\n",
    "        .nunique()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    distribuicao = distribuicao.rename(columns={\"prontuario\": \"Nº de Pacientes Únicos\"})\n",
    "\n",
    "    distribuicao = distribuicao.sort_values(\n",
    "        by=[\"tipo_amostra\", \"Nº de Pacientes Únicos\"], ascending=[True, False]\n",
    "    )\n",
    "\n",
    "    return distribuicao\n",
    "\n",
    "\n",
    "def gerar_aba_base_completa(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Gera a aba com os dados detalhados e selecionados.\"\"\"\n",
    "    colunas_selecionadas = [\n",
    "        \"data_liberacao\",\n",
    "        \"nome_paciente\",\n",
    "        \"prontuario\",\n",
    "        \"unidade_solicitante\",\n",
    "        \"tipo_amostra\",\n",
    "        \"microorganismo\",\n",
    "        \"antibiotico_testado\",\n",
    "        \"resultado_rsi\",\n",
    "        \"valor_mic\",\n",
    "        \"origem_atendimento_simplificada\",\n",
    "        \"tipo_alta\",\n",
    "        \"perfil_resistencia\",\n",
    "    ]\n",
    "    colunas_existentes = [col for col in colunas_selecionadas if col in df.columns]\n",
    "    return df[colunas_existentes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8020a9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 6: FUNÇÃO PARA SALVAR O ARQUIVO EXCEL\n",
    "# ==============================================================================\n",
    "def salvar_relatorio_excel(caminho_saida: Path, abas: dict):\n",
    "    \"\"\"\n",
    "    Salva os DataFrames em um arquivo Excel, com cada um em uma aba.\n",
    "    Aplica formatação automática de largura de coluna.\n",
    "\n",
    "    Args:\n",
    "        caminho_saida (Path): O caminho completo do arquivo .xlsx a ser salvo.\n",
    "        abas (dict): Um dicionário onde as chaves são os nomes das abas e os\n",
    "                     valores são os DataFrames a serem salvos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with pd.ExcelWriter(caminho_saida, engine=\"openpyxl\") as writer:\n",
    "            for nome_aba, df_aba in abas.items():\n",
    "                df_aba.to_excel(writer, sheet_name=nome_aba, index=False)\n",
    "\n",
    "                # Bloco para auto-ajuste da largura das colunas\n",
    "                ws = writer.sheets[nome_aba]\n",
    "                for column in ws.columns:\n",
    "                    max_length = 0\n",
    "                    column_letter = column[0].column_letter\n",
    "                    for cell in column:\n",
    "                        try:\n",
    "                            if len(str(cell.value)) > max_length:\n",
    "                                max_length = len(cell.value)\n",
    "                        except:\n",
    "                            pass\n",
    "                    adjusted_width = max_length + 2\n",
    "                    ws.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "        print(f\"✅ Relatório salvo com sucesso em: {caminho_saida}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao salvar o arquivo Excel: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02820e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 7: FUNÇÃO ORQUESTRADORA PRINCIPAL (VERSÃO CORRIGIDA E FINAL)\n",
    "# ==============================================================================\n",
    "def gerar_relatorio_cciras_mensal(\n",
    "    mes_ano_base: str, pasta_dados: Path, pasta_saida: Path\n",
    "):\n",
    "    \"\"\"\n",
    "    Executa o pipeline completo para gerar o relatório da CCIRAS para um mês.\n",
    "    \"\"\"\n",
    "    # 1. Consolidar os dados brutos usando a nova lógica de merge\n",
    "    df_raw = consolidar_dados_mensais(mes_ano_base, pasta_dados)\n",
    "    if df_raw is None:\n",
    "        return\n",
    "\n",
    "    # 2. Ler arquivos de contagem\n",
    "    try:\n",
    "        df_pos = pd.read_csv(pasta_dados / \"Contagem pacientes amostra positiva.csv\")\n",
    "        df_neg = pd.read_csv(pasta_dados / \"Contagem pacientes amostras negativas.csv\")\n",
    "        contagens = {\"positivos\": len(df_pos), \"negativos\": len(df_neg)}\n",
    "    except FileNotFoundError:\n",
    "        print(\n",
    "            \"⚠️ Arquivos de contagem não encontrados. O Dashboard terá valores zerados.\"\n",
    "        )\n",
    "        contagens = {\"positivos\": 0, \"negativos\": 0}\n",
    "\n",
    "    # 3. Limpar e preparar os dados\n",
    "    df_clean = limpar_e_preparar_dados(df_raw)\n",
    "\n",
    "    # 4. Gerar cada aba analítica\n",
    "    abas_do_relatorio = {\n",
    "        \"Dashboard Indicadores\": gerar_aba_dashboard(df_clean, contagens),\n",
    "        \"Perfil de Sensibilidade\": gerar_aba_perfil_sensibilidade(df_clean),\n",
    "        \"Distribuição por Unidade\": gerar_aba_distribuicao_unidade(df_clean),\n",
    "        \"Distribuição por Amostra\": gerar_aba_distribuicao_amostra(df_clean),\n",
    "        \"Base de Dados Completa\": gerar_aba_base_completa(df_clean),\n",
    "    }\n",
    "\n",
    "    # 5. Salvar o arquivo Excel\n",
    "    nome_arquivo_saida = f\"Relatorio_CCIRAS_HC-UFPE_{mes_ano_base}.xlsx\"\n",
    "    caminho_completo_saida = pasta_saida / nome_arquivo_saida\n",
    "    salvar_relatorio_excel(caminho_completo_saida, abas_do_relatorio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee24429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================== INICIANDO PROCESSAMENTO PARA O ANO 2025 ====================\n",
      "Bases 'vigiram' encontradas para 2025: abr25, fev25, jan25, jun25, mai25, mar25\n",
      "🔄 Processando base: abr25...\n",
      "✅ Dados de 'abr25' consolidados. Fonte de amostra ('Material Análise' do ITS) vinculada.\n",
      "✅ Relatório salvo com sucesso em: C:\\Users\\marcelo.petry\\Documents\\CCIRAS\\vigiram\\outputs\\Relatorio_CCIRAS_HC-UFPE_abr25.xlsx\n",
      "----------------------------------------------------------------------\n",
      "🔄 Processando base: fev25...\n",
      "✅ Dados de 'fev25' consolidados. Fonte de amostra ('Material Análise' do ITS) vinculada.\n",
      "✅ Relatório salvo com sucesso em: C:\\Users\\marcelo.petry\\Documents\\CCIRAS\\vigiram\\outputs\\Relatorio_CCIRAS_HC-UFPE_fev25.xlsx\n",
      "----------------------------------------------------------------------\n",
      "🔄 Processando base: jan25...\n",
      "✅ Dados de 'jan25' consolidados. Fonte de amostra ('Material Análise' do ITS) vinculada.\n",
      "✅ Relatório salvo com sucesso em: C:\\Users\\marcelo.petry\\Documents\\CCIRAS\\vigiram\\outputs\\Relatorio_CCIRAS_HC-UFPE_jan25.xlsx\n",
      "----------------------------------------------------------------------\n",
      "🔄 Processando base: jun25...\n",
      "✅ Dados de 'jun25' consolidados. Fonte de amostra ('Material Análise' do ITS) vinculada.\n",
      "✅ Relatório salvo com sucesso em: C:\\Users\\marcelo.petry\\Documents\\CCIRAS\\vigiram\\outputs\\Relatorio_CCIRAS_HC-UFPE_jun25.xlsx\n",
      "----------------------------------------------------------------------\n",
      "🔄 Processando base: mai25...\n",
      "✅ Dados de 'mai25' consolidados. Fonte de amostra ('Material Análise' do ITS) vinculada.\n",
      "✅ Relatório salvo com sucesso em: C:\\Users\\marcelo.petry\\Documents\\CCIRAS\\vigiram\\outputs\\Relatorio_CCIRAS_HC-UFPE_mai25.xlsx\n",
      "----------------------------------------------------------------------\n",
      "🔄 Processando base: mar25...\n",
      "✅ Dados de 'mar25' consolidados. Fonte de amostra ('Material Análise' do ITS) vinculada.\n",
      "✅ Relatório salvo com sucesso em: C:\\Users\\marcelo.petry\\Documents\\CCIRAS\\vigiram\\outputs\\Relatorio_CCIRAS_HC-UFPE_mar25.xlsx\n",
      "----------------------------------------------------------------------\n",
      "🏁 Processamento para o ano 2025 finalizado. 🏁\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CÉLULA 8: EXECUÇÃO DO PROCESSO (VERSÃO CORRIGIDA)\n",
    "# ==============================================================================\n",
    "def processar_ano_completo(ano_2d: str, pasta_dados: Path, pasta_saida: Path):\n",
    "    \"\"\"\n",
    "    Encontra todos os arquivos de um ano e executa o gerador de relatórios para cada um.\n",
    "    \"\"\"\n",
    "    print(f\"\\n\\n{'='*20} INICIANDO PROCESSAMENTO PARA O ANO 20{ano_2d} {'='*20}\")\n",
    "\n",
    "    # **AQUI ESTÁ A MUDANÇA PRINCIPAL**: Padrão para encontrar arquivos como 'vigiram-jan25.csv'\n",
    "    padrao = re.compile(rf\"vigiram-([a-z]{{3}}{ano_2d})\\.csv\", re.IGNORECASE)\n",
    "\n",
    "    arquivos_encontrados = [padrao.match(f) for f in os.listdir(pasta_dados)]\n",
    "    bases_de_mes = sorted(list(set(m.group(1) for m in arquivos_encontrados if m)))\n",
    "\n",
    "    if not bases_de_mes:\n",
    "        print(\n",
    "            f\"Nenhuma base de dados 'vigiram-*.csv' encontrada para o ano 20{ano_2d} na pasta {pasta_dados}\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    print(f\"Bases 'vigiram' encontradas para 20{ano_2d}: {', '.join(bases_de_mes)}\")\n",
    "\n",
    "    for mes_ano_base in bases_de_mes:\n",
    "        gerar_relatorio_cciras_mensal(mes_ano_base, pasta_dados, pasta_saida)\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "    print(f\"🏁 Processamento para o ano 20{ano_2d} finalizado. 🏁\")\n",
    "\n",
    "\n",
    "# --- PONTO DE PARTIDA: DEFINA O ANO A SER PROCESSADO AQUI ---\n",
    "ANO_A_PROCESSAR = \"25\"  # Ex: \"24\" para 2024, \"25\" para 2025\n",
    "processar_ano_completo(ANO_A_PROCESSAR, DATA_DIR, OUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
